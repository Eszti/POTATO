{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def d_clean(string):\n",
    "    s = string\n",
    "    for c in '\\\\=@-,\\'\".!:;<>/{}[]()#^?':\n",
    "        s = s.replace(c, '_')\n",
    "    s = s.replace('$', '_dollars')\n",
    "    s = s.replace('%', '_percent')\n",
    "    s = s.replace('|', ' ')\n",
    "    s = s.replace('*', ' ')\n",
    "    if s == '#':\n",
    "        s = '_number'\n",
    "    keywords = (\"graph\", \"node\", \"strict\", \"edge\")\n",
    "    if re.match('^[0-9]', s) or s in keywords:\n",
    "        s = \"X\" + s\n",
    "        \n",
    "    if not s:\n",
    "        return \"None\"\n",
    "    return s\n",
    "\n",
    "def to_dots(graphs, marked_nodes=set(), integ=False):\n",
    "    lines = [u'digraph finite_state_machine {', '\\tdpi=70;']\n",
    "    # lines.append('\\tordering=out;')\n",
    "    # sorting everything to make the process deterministic\n",
    "    for i, graph in enumerate(graphs):\n",
    "        s = \"subgraph cluster_\" + chr(ord('@')+i+1) + \" {\"\n",
    "        node_lines = []\n",
    "\n",
    "        node_lines.append(s)\n",
    "        node_to_name = {}\n",
    "        for node, n_data in graph.nodes(data=True):\n",
    "            if integ:\n",
    "                d_node = d_clean(str(node))\n",
    "            else:    \n",
    "                d_node = d_clean(n_data[\"name\"])\n",
    "            printname = d_node\n",
    "            node_to_name[node] = printname\n",
    "            if 'expanded' in n_data and n_data['expanded'] and printname in marked_nodes:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                        style=filled, fillcolor=purple];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            elif 'expanded' in n_data and n_data['expanded']:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                        style=\"filled\"];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            elif 'fourlang' in n_data and n_data['fourlang']:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                        style=\"filled\", fillcolor=red];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            elif 'substituted' in n_data and n_data['substituted']:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                        style=\"filled\"];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            elif printname in marked_nodes:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\", style=filled, fillcolor=lightblue];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            else:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\"];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            node_lines.append(node_line)\n",
    "        lines += sorted(node_lines)\n",
    "\n",
    "        edge_lines = []\n",
    "        for u, v, edata in graph.edges(data=True):\n",
    "            if 'color' in edata:\n",
    "                d_node1 = node_to_name[u]\n",
    "                d_node2 = node_to_name[v]\n",
    "                edge_lines.append(\n",
    "                    u'\\t{0} -> {1} [ label = \"{2}\" ];'.format(d_node1, d_node2, edata['color']))\n",
    "\n",
    "        lines += sorted(edge_lines)\n",
    "        lines.append('}')\n",
    "    lines.append('}')\n",
    "    return u'\\n'.join(lines)\n",
    "\n",
    "def to_dot(graph, marked_nodes=set(), integ=False):\n",
    "    lines = [u'digraph finite_state_machine {', '\\tdpi=70;']\n",
    "    # lines.append('\\tordering=out;')\n",
    "    # sorting everything to make the process deterministic\n",
    "    node_lines = []\n",
    "    node_to_name = {}\n",
    "    for node, n_data in graph.nodes(data=True):\n",
    "        if integ:\n",
    "            d_node = d_clean(str(node))\n",
    "        else:    \n",
    "            d_node = d_clean(n_data[\"name\"])\n",
    "        printname = d_node\n",
    "        node_to_name[node] = printname\n",
    "        if 'expanded' in n_data and n_data['expanded'] and printname in marked_nodes:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                    style=filled, fillcolor=purple];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        elif 'expanded' in n_data and n_data['expanded']:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                    style=\"filled\"];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        elif 'fourlang' in n_data and n_data['fourlang']:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                    style=\"filled\", fillcolor=red];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        elif 'substituted' in n_data and n_data['substituted']:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                    style=\"filled\"];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        elif printname in marked_nodes:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\", style=filled, fillcolor=lightblue];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        else:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\"];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        node_lines.append(node_line)\n",
    "    lines += sorted(node_lines)\n",
    "\n",
    "    edge_lines = []\n",
    "    for u, v, edata in graph.edges(data=True):\n",
    "        if 'color' in edata:\n",
    "            d_node1 = node_to_name[u]\n",
    "            d_node2 = node_to_name[v]\n",
    "            edge_lines.append(\n",
    "                u'\\t{0} -> {1} [ label = \"{2}\" ];'.format(d_node1, d_node2, edata['color']))\n",
    "\n",
    "    lines += sorted(edge_lines)\n",
    "    lines.append('}')\n",
    "    return u'\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exprel.dataset.hasoc_dataset import HasocDataset\n",
    "from exprel.models.utils import tree_to_code\n",
    "from dotenv import load_dotenv \n",
    "import pandas as pd\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/home/kovacs/projects/exp-relation-extraction/data/hasoc_2021_train_normalized.csv\", delimiter=\"\\t\")\n",
    "df_test = pd.read_csv(\"/home/kovacs/projects/exp-relation-extraction/data/hasoc_2021_test_normalized.csv\", delimiter=\"\\t\")\n",
    "train_data = HasocDataset(df_train)\n",
    "test_data = HasocDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exprel.feature_extractor.extract import FeatureExtractor\n",
    "from exprel.models.model import GraphModel\n",
    "\n",
    "extractor = FeatureExtractor(lang=\"en\", cache_fn=\"en_nlp_cache\")\n",
    "model = GraphModel()\n",
    "test_model = GraphModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.load_graphs(\"/home/kovacs/projects/exp-relation-extraction/notebooks/graphs/hasoc2021_train_amr.pickle\")\n",
    "test_data.load_graphs(\"/home/kovacs/projects/exp-relation-extraction/notebooks/graphs/hasoc2021_test_amr.pickle\")\n",
    "#graphs = data.parse_graphs(extractor, format=\"fourlang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_data.to_dataframe()\n",
    "df_test = test_data.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ids = pd.to_numeric(df_train.index).tolist()\n",
    "sentences = df_train.preprocessed_text.tolist()\n",
    "labels = df_train.task2_id.tolist()\n",
    "postprocessed_graphs = df_train.graph.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for ind, graph, label in tqdm(zip(ids, postprocessed_graphs, labels)):\n",
    "    model.featurize_sen_graph(ind, graph, label, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_ids = pd.to_numeric(df_test.index).tolist()\n",
    "test_sentences = df_test.preprocessed_text.tolist()\n",
    "test_labels = df_test.task2_id.tolist()\n",
    "test_postprocessed_graphs = df_test.graph.tolist()\n",
    "\n",
    "for ind, graph, label in tqdm(zip(test_ids, test_postprocessed_graphs, test_labels)):\n",
    "    test_model.featurize_sen_graph(ind, graph, label, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_graphs = model.get_feature_graphs()\n",
    "test_feature_graphs = test_model.get_feature_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.select_n_best(2500)\n",
    "test_model.select_n_best(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vocab = {\"NONE\": 0, \"PRFN\": 1, \"OFFN\": 2, \"HATE\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = model.get_x_y(df_train.task2, label_vocab=label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, _ = test_model.get_x_y(df_test.task2, label_vocab = {None: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "tr_data,tst_data,tr_labels,tst_labels = split(X,Y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#clf = LogisticRegression(random_state=0).fit(tr_data, tr_labels)\n",
    "clf = OneVsRestClassifier(RandomForestClassifier(random_state=0, class_weight=\"balanced_subsample\")).fit(tr_data, tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "keys = [\"NONE\", \"PRFN\", \"OFFN\", \"HATE\"]\n",
    "labels_to_result = {}\n",
    "lr_pred = clf.predict(tst_data)\n",
    "#prf = precision_recall_fscore_support(tst_labels, lr_pred, average=None)\n",
    "print(classification_report(tst_labels, lr_pred, target_names=keys, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_graph_strings = model.get_feature_graph_strings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = eli5.explain_weights_df(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "features = defaultdict(list)\n",
    "\n",
    "for target in weights_df.target.unique():\n",
    "    targeted_df = weights_df[weights_df.target == target]\n",
    "    most_important_weights = targeted_df.iloc[:5].feature.str.strip(\"x\").tolist()\n",
    "    for i in most_important_weights:\n",
    "        if i != \"<BIAS>\":\n",
    "            g_nx = feature_graphs[model.inverse_relabel[int(i)]]\n",
    "            #if len(g_nx.edges()):\n",
    "            g = feature_graph_strings[model.inverse_relabel[int(i)]]\n",
    "            features[list(keys)[int(target)]].append(([g], [], {v: k for k, v in label_vocab.items()}[int(target)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "from collections import defaultdict\n",
    "features = defaultdict(list)\n",
    "\n",
    "for j, est in enumerate(clf.estimators_):\n",
    "    weights_df = eli5.explain_weights_df(est)\n",
    "    most_important_weights = weights_df.iloc[:5].feature.str.strip(\"x\").tolist()\n",
    "    for i in most_important_weights:\n",
    "        if i != \"<BIAS>\":\n",
    "            g_nx = feature_graphs[model.inverse_relabel[int(i)]]\n",
    "            #if len(g_nx.edges()):\n",
    "            g = feature_graph_strings[model.inverse_relabel[int(i)]]\n",
    "            features[list(keys)[j]].append(([g], [], model.label_vocab.id_to_word[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"2021_train_features_task2.json\", \"w+\") as f:\n",
    "    json.dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = split(df_train, test_size=0.2, random_state=1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={'preprocessed_text': 'sentence', 'task2': 'label'})\n",
    "val = val.rename(columns={'preprocessed_text': 'sentence', 'task2': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle(\"train_dataset\")\n",
    "val.to_pickle(\"val_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-synthesis",
   "metadata": {},
   "source": [
    "## Simple Ngram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=2500, stop_words=\"english\", lowercase=True, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit(train.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.transform(train.sentence)\n",
    "X_val = X.transform(val.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = OneVsRestClassifier(RandomForestClassifier(random_state=0, class_weight=\"balanced_subsample\")).fit(X_train, tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "keys = [\"NONE\", \"PRFN\", \"OFFN\", \"HATE\"]\n",
    "labels_to_result = {}\n",
    "lr_pred2 = clf2.predict(X_val)\n",
    "print(classification_report(tst_labels, lr_pred2, target_names=keys, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = clf2.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "amr = clf.predict_proba(tst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voted = ngram + amr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds = np.argmax(soft_voted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tst_labels, preds, target_names=keys, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_predict = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_predict = clf2.predict(X.transform(df_test.preprocessed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voted = clf2.predict_proba(X.transform(df_test.preprocessed_text)) + clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_preds = np.argmax(soft_voted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_vocab = {v: k for k, v in label_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.DataFrame({\"sentence\": df_test.preprocessed_text, \"graph_pred\": [inverse_vocab[i] for i in amr_predict], \"ngram_pred\": [inverse_vocab[i] for i in ngram_predict], \"soft_vote\": [inverse_vocab[i] for i in test_preds]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.to_csv(\"2021_hasoc_test_taskB.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_labels = []\n",
    "with open(\"2021_rule_labels\") as f:\n",
    "    for line in f:\n",
    "        rule_labels.append(line.strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proba = clf2.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_argmax = []\n",
    "for i, proba in enumerate(val_proba):\n",
    "    L = np.argsort(-proba)\n",
    "    if L[0] == 0 and rule_labels[i] == \"HOF\":\n",
    "        p\n",
    "        rule_argmax.append(L[1])\n",
    "    else:\n",
    "        rule_argmax.append(L[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tst_labels, rule_argmax, target_names=keys, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-producer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
